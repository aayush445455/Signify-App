{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fba52ec2-5c01-4c55-9967-99f9ff52dd74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned to 30 labels: ['hello', 'goodbye', 'go', 'again', 'because', 'but', 'blue', 'family', 'come', 'like', 'help', 'eat', 'drink', 'know', 'learn', 'can', 'cannot', 'make', 'give', 'get', 'find', 'ask', 'close', 'love', 'good', 'child', 'enjoy', 'more', 'far', 'big']\n",
      "Filtered 444 samples across 30 classes → saved to D:\\Projects\\data\\filtered_top30.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports, Parameters & Directory Setup (Improved)\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ——— PARAMETERS ———\n",
    "DATA_ROOT     = r\"D:\\Projects\\data\"\n",
    "METADATA_CSV  = os.path.join(DATA_ROOT, \"metadata.csv\")\n",
    "\n",
    "# Your original mandatory list; we'll prune it to the top 30 that actually exist\n",
    "CLASS_LIST = [\n",
    "    \"hello\",\"goodbye\",\"please\",\"thank\",\"sorry\",\"go\",\"again\",\"because\",\"but\",\"blue\",\n",
    "    \"family\",\"come\",\"want\",\"like\",\"need\",\"help\",\"eat\",\"drink\",\"see\",\"look\",\"know\",\n",
    "    \"learn\",\"read\",\"write\",\"talk\",\"say\",\"speak\",\"understand\",\"can\",\"cannot\",\"do\",\n",
    "    \"does\",\"did\",\"will\",\"shall\",\"make\",\"give\",\"get\",\"find\",\"show\",\"ask\",\"tell\",\n",
    "    \"work\",\"walk\",\"run\",\"sit\",\"stand\",\"open\",\"close\",\"stop\",\"start\",\"begin\",\"love\",\n",
    "    \"good\",\"child\",\"enjoy\",\"more\",\"far\",\"big\",\"before\",\"man\",\"how\",\"boy\",\"angry\",\n",
    "    \"black\",\"fine\",\"bad\",\"late\",\"bathroom\"\n",
    "]\n",
    "NUM_CLASSES   = 30\n",
    "\n",
    "# Directories for new pipeline outputs\n",
    "AUG_DIR       = os.path.join(DATA_ROOT, \"augment1\")\n",
    "LANDMARK_DIR  = os.path.join(DATA_ROOT, \"landmark1\")\n",
    "\n",
    "# Create dirs if they don't exist (won't overwrite existing data)\n",
    "os.makedirs(AUG_DIR,      exist_ok=True)\n",
    "os.makedirs(LANDMARK_DIR, exist_ok=True)\n",
    "\n",
    "# ——— LOAD & PRUNE METADATA ———\n",
    "assert os.path.exists(METADATA_CSV), f\"Missing metadata: {METADATA_CSV}\"\n",
    "df_full      = pd.read_csv(METADATA_CSV)\n",
    "labels_exist = set(df_full['Label'].unique())\n",
    "\n",
    "# Keep only the first 30 of your mandatory signs that actually exist in the data\n",
    "TOP30        = [w for w in CLASS_LIST if w in labels_exist][:NUM_CLASSES]\n",
    "print(f\"Pruned to {len(TOP30)} labels:\", TOP30)\n",
    "\n",
    "# Filter and reset index\n",
    "df           = df_full[df_full['Label'].isin(TOP30)].copy().reset_index(drop=True)\n",
    "\n",
    "# Expand file paths to full absolute paths\n",
    "df['Filepath'] = df['Filepath'].apply(lambda p: os.path.join(DATA_ROOT, p))\n",
    "\n",
    "# Map each label to an integer index\n",
    "label_to_idx   = {lab: i for i, lab in enumerate(TOP30)}\n",
    "df['LabelIdx'] = df['Label'].map(label_to_idx)\n",
    "\n",
    "# Save filtered metadata for downstream cells\n",
    "filtered_csv = os.path.join(DATA_ROOT, 'filtered_top30.csv')\n",
    "df.to_csv(filtered_csv, index=False)\n",
    "print(f\"Filtered {len(df)} samples across {len(TOP30)} classes → saved to {filtered_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6d5ee66-1e2e-4b5b-aa83-343dcc675cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[001] Augmented '02485' → D:\\Projects\\data\\augment1\\again\n",
      "[002] Augmented '02487' → D:\\Projects\\data\\augment1\\again\n",
      "[003] Augmented '02490' → D:\\Projects\\data\\augment1\\again\n",
      "[004] Augmented '02518' → D:\\Projects\\data\\augment1\\again\n",
      "[005] Augmented '02519' → D:\\Projects\\data\\augment1\\again\n",
      "[006] Augmented '02521' → D:\\Projects\\data\\augment1\\again\n",
      "[007] Augmented '02525' → D:\\Projects\\data\\augment1\\again\n",
      "[008] Augmented '02540' → D:\\Projects\\data\\augment1\\again\n",
      "[009] Augmented '02541' → D:\\Projects\\data\\augment1\\again\n",
      "[010] Augmented '02542' → D:\\Projects\\data\\augment1\\again\n",
      "[011] Augmented '02544' → D:\\Projects\\data\\augment1\\again\n",
      "[012] Augmented '02545' → D:\\Projects\\data\\augment1\\again\n",
      "[013] Augmented '02548' → D:\\Projects\\data\\augment1\\again\n",
      "[014] Augmented '06552' → D:\\Projects\\data\\augment1\\ask\n",
      "[015] Augmented '06553' → D:\\Projects\\data\\augment1\\ask\n",
      "[016] Augmented '06554' → D:\\Projects\\data\\augment1\\ask\n",
      "[017] Augmented '06555' → D:\\Projects\\data\\augment1\\ask\n",
      "[018] Augmented '06558' → D:\\Projects\\data\\augment1\\ask\n",
      "[019] Augmented '06559' → D:\\Projects\\data\\augment1\\ask\n",
      "[020] Augmented '06613' → D:\\Projects\\data\\augment1\\ask\n",
      "[021] Augmented '06614' → D:\\Projects\\data\\augment1\\ask\n",
      "[022] Augmented '06615' → D:\\Projects\\data\\augment1\\ask\n",
      "[023] Augmented '06618' → D:\\Projects\\data\\augment1\\ask\n",
      "[024] Augmented '10091' → D:\\Projects\\data\\augment1\\because\n",
      "[025] Augmented '10093' → D:\\Projects\\data\\augment1\\because\n",
      "[026] Augmented '10096' → D:\\Projects\\data\\augment1\\because\n",
      "[027] Augmented '10102' → D:\\Projects\\data\\augment1\\because\n",
      "[028] Augmented '10104' → D:\\Projects\\data\\augment1\\because\n",
      "[029] Augmented '10105' → D:\\Projects\\data\\augment1\\because\n",
      "[030] Augmented '10106' → D:\\Projects\\data\\augment1\\because\n",
      "[031] Augmented '10107' → D:\\Projects\\data\\augment1\\because\n",
      "[032] Augmented '10109' → D:\\Projects\\data\\augment1\\because\n",
      "[033] Augmented '10111' → D:\\Projects\\data\\augment1\\because\n",
      "[034] Augmented '10112' → D:\\Projects\\data\\augment1\\because\n",
      "[035] Augmented '10135' → D:\\Projects\\data\\augment1\\because\n",
      "[036] Augmented '10136' → D:\\Projects\\data\\augment1\\because\n",
      "[037] Augmented '10137' → D:\\Projects\\data\\augment1\\because\n",
      "[038] Augmented '10138' → D:\\Projects\\data\\augment1\\because\n",
      "[039] Augmented '10141' → D:\\Projects\\data\\augment1\\because\n",
      "[040] Augmented '11862' → D:\\Projects\\data\\augment1\\big\n",
      "[041] Augmented '11863' → D:\\Projects\\data\\augment1\\big\n",
      "[042] Augmented '11864' → D:\\Projects\\data\\augment1\\big\n",
      "[043] Augmented '11865' → D:\\Projects\\data\\augment1\\big\n",
      "[044] Augmented '11866' → D:\\Projects\\data\\augment1\\big\n",
      "[045] Augmented '11867' → D:\\Projects\\data\\augment1\\big\n",
      "[046] Augmented '11872' → D:\\Projects\\data\\augment1\\big\n",
      "[047] Augmented '11876' → D:\\Projects\\data\\augment1\\big\n",
      "[048] Augmented '11877' → D:\\Projects\\data\\augment1\\big\n",
      "[049] Augmented '11878' → D:\\Projects\\data\\augment1\\big\n",
      "[050] Augmented '11882' → D:\\Projects\\data\\augment1\\big\n",
      "[051] Augmented '11884' → D:\\Projects\\data\\augment1\\big\n",
      "[052] Augmented '12994' → D:\\Projects\\data\\augment1\\blue\n",
      "[053] Augmented '13017' → D:\\Projects\\data\\augment1\\blue\n",
      "[054] Augmented '13018' → D:\\Projects\\data\\augment1\\blue\n",
      "[055] Augmented '13019' → D:\\Projects\\data\\augment1\\blue\n",
      "[056] Augmented '13020' → D:\\Projects\\data\\augment1\\blue\n",
      "[057] Augmented '13023' → D:\\Projects\\data\\augment1\\blue\n",
      "[058] Augmented '13024' → D:\\Projects\\data\\augment1\\blue\n",
      "[059] Augmented '13026' → D:\\Projects\\data\\augment1\\blue\n",
      "[060] Augmented '13042' → D:\\Projects\\data\\augment1\\blue\n",
      "[061] Augmented '13043' → D:\\Projects\\data\\augment1\\blue\n",
      "[062] Augmented '13044' → D:\\Projects\\data\\augment1\\blue\n",
      "[063] Augmented '13046' → D:\\Projects\\data\\augment1\\blue\n",
      "[064] Augmented '15941' → D:\\Projects\\data\\augment1\\but\n",
      "[065] Augmented '15957' → D:\\Projects\\data\\augment1\\but\n",
      "[066] Augmented '15958' → D:\\Projects\\data\\augment1\\but\n",
      "[067] Augmented '15996' → D:\\Projects\\data\\augment1\\but\n",
      "[068] Augmented '15998' → D:\\Projects\\data\\augment1\\but\n",
      "[069] Augmented '16000' → D:\\Projects\\data\\augment1\\but\n",
      "[070] Augmented '16002' → D:\\Projects\\data\\augment1\\but\n",
      "[071] Augmented '16004' → D:\\Projects\\data\\augment1\\but\n",
      "[072] Augmented '16005' → D:\\Projects\\data\\augment1\\but\n",
      "[073] Augmented '16007' → D:\\Projects\\data\\augment1\\but\n",
      "[074] Augmented '16009' → D:\\Projects\\data\\augment1\\but\n",
      "[075] Augmented '16061' → D:\\Projects\\data\\augment1\\but\n",
      "[076] Augmented '17589' → D:\\Projects\\data\\augment1\\can\n",
      "[077] Augmented '17594' → D:\\Projects\\data\\augment1\\can\n",
      "[078] Augmented '17595' → D:\\Projects\\data\\augment1\\can\n",
      "[079] Augmented '17596' → D:\\Projects\\data\\augment1\\can\n",
      "[080] Augmented '17600' → D:\\Projects\\data\\augment1\\can\n",
      "[081] Augmented '17607' → D:\\Projects\\data\\augment1\\can\n",
      "[082] Augmented '17627' → D:\\Projects\\data\\augment1\\can\n",
      "[083] Augmented '17628' → D:\\Projects\\data\\augment1\\can\n",
      "[084] Augmented '17633' → D:\\Projects\\data\\augment1\\can\n",
      "[085] Augmented '17636' → D:\\Projects\\data\\augment1\\can\n",
      "[086] Augmented '17654' → D:\\Projects\\data\\augment1\\can\n",
      "[087] Augmented '17655' → D:\\Projects\\data\\augment1\\can\n",
      "[088] Augmented '17656' → D:\\Projects\\data\\augment1\\can\n",
      "[089] Augmented '17657' → D:\\Projects\\data\\augment1\\can\n",
      "[090] Augmented '17659' → D:\\Projects\\data\\augment1\\cannot\n",
      "[091] Augmented '17660' → D:\\Projects\\data\\augment1\\cannot\n",
      "[092] Augmented '17665' → D:\\Projects\\data\\augment1\\cannot\n",
      "[093] Augmented '17709' → D:\\Projects\\data\\augment1\\cannot\n",
      "[094] Augmented '17710' → D:\\Projects\\data\\augment1\\cannot\n",
      "[095] Augmented '17711' → D:\\Projects\\data\\augment1\\cannot\n",
      "[096] Augmented '17712' → D:\\Projects\\data\\augment1\\cannot\n",
      "[097] Augmented '17713' → D:\\Projects\\data\\augment1\\cannot\n",
      "[098] Augmented '17720' → D:\\Projects\\data\\augment1\\cannot\n",
      "[099] Augmented '17721' → D:\\Projects\\data\\augment1\\cannot\n",
      "[100] Augmented '20661' → D:\\Projects\\data\\augment1\\child\n",
      "[101] Augmented '20662' → D:\\Projects\\data\\augment1\\child\n",
      "[102] Augmented '20665' → D:\\Projects\\data\\augment1\\child\n",
      "[103] Augmented '20667' → D:\\Projects\\data\\augment1\\child\n",
      "[104] Augmented '20699' → D:\\Projects\\data\\augment1\\child\n",
      "[105] Augmented '20700' → D:\\Projects\\data\\augment1\\child\n",
      "[106] Augmented '20701' → D:\\Projects\\data\\augment1\\child\n",
      "[107] Augmented '20702' → D:\\Projects\\data\\augment1\\child\n",
      "[108] Augmented '20706' → D:\\Projects\\data\\augment1\\child\n",
      "[109] Augmented '20711' → D:\\Projects\\data\\augment1\\child\n",
      "[110] Augmented '20737' → D:\\Projects\\data\\augment1\\child\n",
      "[111] Augmented '20739' → D:\\Projects\\data\\augment1\\child\n",
      "[112] Augmented '20740' → D:\\Projects\\data\\augment1\\child\n",
      "[113] Augmented '20741' → D:\\Projects\\data\\augment1\\child\n",
      "[114] Augmented '20746' → D:\\Projects\\data\\augment1\\child\n",
      "[115] Augmented '20766' → D:\\Projects\\data\\augment1\\child\n",
      "[116] Augmented '22489' → D:\\Projects\\data\\augment1\\close\n",
      "[117] Augmented '22492' → D:\\Projects\\data\\augment1\\close\n",
      "[118] Augmented '22493' → D:\\Projects\\data\\augment1\\close\n",
      "[119] Augmented '22494' → D:\\Projects\\data\\augment1\\close\n",
      "[120] Augmented '22495' → D:\\Projects\\data\\augment1\\close\n",
      "[121] Augmented '22499' → D:\\Projects\\data\\augment1\\close\n",
      "[122] Augmented '22502' → D:\\Projects\\data\\augment1\\close\n",
      "[123] Augmented '22510' → D:\\Projects\\data\\augment1\\close\n",
      "[124] Augmented '22511' → D:\\Projects\\data\\augment1\\close\n",
      "[125] Augmented '22512' → D:\\Projects\\data\\augment1\\close\n",
      "[126] Augmented '22514' → D:\\Projects\\data\\augment1\\close\n",
      "[127] Augmented '22548' → D:\\Projects\\data\\augment1\\close\n",
      "[128] Augmented '22549' → D:\\Projects\\data\\augment1\\close\n",
      "[129] Augmented '22550' → D:\\Projects\\data\\augment1\\close\n",
      "[130] Augmented '22551' → D:\\Projects\\data\\augment1\\close\n",
      "[131] Augmented '22553' → D:\\Projects\\data\\augment1\\close\n",
      "[132] Augmented '23859' → D:\\Projects\\data\\augment1\\come\n",
      "[133] Augmented '23868' → D:\\Projects\\data\\augment1\\come\n",
      "[134] Augmented '23869' → D:\\Projects\\data\\augment1\\come\n",
      "[135] Augmented '23870' → D:\\Projects\\data\\augment1\\come\n",
      "[136] Augmented '23873' → D:\\Projects\\data\\augment1\\come\n",
      "[137] Augmented '23878' → D:\\Projects\\data\\augment1\\come\n",
      "[138] Augmented '23902' → D:\\Projects\\data\\augment1\\come\n",
      "[139] Augmented '23907' → D:\\Projects\\data\\augment1\\come\n",
      "[140] Augmented '23913' → D:\\Projects\\data\\augment1\\come\n",
      "[141] Augmented '23946' → D:\\Projects\\data\\augment1\\come\n",
      "[142] Augmented '37958' → D:\\Projects\\data\\augment1\\drink\n",
      "[143] Augmented '37959' → D:\\Projects\\data\\augment1\\drink\n",
      "[144] Augmented '37961' → D:\\Projects\\data\\augment1\\drink\n",
      "[145] Augmented '37962' → D:\\Projects\\data\\augment1\\drink\n",
      "[146] Augmented '37967' → D:\\Projects\\data\\augment1\\drink\n",
      "[147] Augmented '37984' → D:\\Projects\\data\\augment1\\drink\n",
      "[148] Augmented '37985' → D:\\Projects\\data\\augment1\\drink\n",
      "[149] Augmented '37986' → D:\\Projects\\data\\augment1\\drink\n",
      "[150] Augmented '37987' → D:\\Projects\\data\\augment1\\drink\n",
      "[151] Augmented '37989' → D:\\Projects\\data\\augment1\\drink\n",
      "[152] Augmented '37993' → D:\\Projects\\data\\augment1\\drink\n",
      "[153] Augmented '38011' → D:\\Projects\\data\\augment1\\drink\n",
      "[154] Augmented '38012' → D:\\Projects\\data\\augment1\\drink\n",
      "[155] Augmented '38013' → D:\\Projects\\data\\augment1\\drink\n",
      "[156] Augmented '38014' → D:\\Projects\\data\\augment1\\drink\n",
      "[157] Augmented '38015' → D:\\Projects\\data\\augment1\\drink\n",
      "[158] Augmented '38019' → D:\\Projects\\data\\augment1\\drink\n",
      "[159] Augmented '38021' → D:\\Projects\\data\\augment1\\drink\n",
      "[160] Augmented '38043' → D:\\Projects\\data\\augment1\\drink\n",
      "[161] Augmented '38044' → D:\\Projects\\data\\augment1\\drink\n",
      "[162] Augmented '38045' → D:\\Projects\\data\\augment1\\drink\n",
      "[163] Augmented '38047' → D:\\Projects\\data\\augment1\\drink\n",
      "[164] Augmented '38048' → D:\\Projects\\data\\augment1\\drink\n",
      "[165] Augmented '38062' → D:\\Projects\\data\\augment1\\drink\n",
      "[166] Augmented '39850' → D:\\Projects\\data\\augment1\\eat\n",
      "[167] Augmented '39851' → D:\\Projects\\data\\augment1\\eat\n",
      "[168] Augmented '39853' → D:\\Projects\\data\\augment1\\eat\n",
      "[169] Augmented '39854' → D:\\Projects\\data\\augment1\\eat\n",
      "[170] Augmented '39857' → D:\\Projects\\data\\augment1\\eat\n",
      "[171] Augmented '39874' → D:\\Projects\\data\\augment1\\eat\n",
      "[172] Augmented '39875' → D:\\Projects\\data\\augment1\\eat\n",
      "[173] Augmented '39877' → D:\\Projects\\data\\augment1\\eat\n",
      "[174] Augmented '39878' → D:\\Projects\\data\\augment1\\eat\n",
      "[175] Augmented '39879' → D:\\Projects\\data\\augment1\\eat\n",
      "[176] Augmented '42004' → D:\\Projects\\data\\augment1\\enjoy\n",
      "[177] Augmented '42005' → D:\\Projects\\data\\augment1\\enjoy\n",
      "[178] Augmented '42008' → D:\\Projects\\data\\augment1\\enjoy\n",
      "[179] Augmented '42039' → D:\\Projects\\data\\augment1\\enjoy\n",
      "[180] Augmented '42040' → D:\\Projects\\data\\augment1\\enjoy\n",
      "[181] Augmented '42041' → D:\\Projects\\data\\augment1\\enjoy\n",
      "[182] Augmented '42044' → D:\\Projects\\data\\augment1\\enjoy\n",
      "[183] Augmented '42045' → D:\\Projects\\data\\augment1\\enjoy\n",
      "[184] Augmented '42076' → D:\\Projects\\data\\augment1\\enjoy\n",
      "[185] Augmented '42080' → D:\\Projects\\data\\augment1\\enjoy\n",
      "[186] Augmented '42086' → D:\\Projects\\data\\augment1\\enjoy\n",
      "[187] Augmented '42088' → D:\\Projects\\data\\augment1\\enjoy\n",
      "[188] Augmented '42137' → D:\\Projects\\data\\augment1\\enjoy\n",
      "[189] Augmented '42138' → D:\\Projects\\data\\augment1\\enjoy\n",
      "[190] Augmented '44843' → D:\\Projects\\data\\augment1\\family\n",
      "[191] Augmented '44844' → D:\\Projects\\data\\augment1\\family\n",
      "[192] Augmented '44847' → D:\\Projects\\data\\augment1\\family\n",
      "[193] Augmented '44849' → D:\\Projects\\data\\augment1\\family\n",
      "[194] Augmented '44860' → D:\\Projects\\data\\augment1\\family\n",
      "[195] Augmented '44862' → D:\\Projects\\data\\augment1\\family\n",
      "[196] Augmented '44863' → D:\\Projects\\data\\augment1\\family\n",
      "[197] Augmented '44865' → D:\\Projects\\data\\augment1\\family\n",
      "[198] Augmented '44868' → D:\\Projects\\data\\augment1\\family\n",
      "[199] Augmented '44869' → D:\\Projects\\data\\augment1\\family\n",
      "[200] Augmented '44897' → D:\\Projects\\data\\augment1\\family\n",
      "[201] Augmented '44898' → D:\\Projects\\data\\augment1\\family\n",
      "[202] Augmented '44900' → D:\\Projects\\data\\augment1\\family\n",
      "[203] Augmented '44903' → D:\\Projects\\data\\augment1\\family\n",
      "[204] Augmented '44906' → D:\\Projects\\data\\augment1\\family\n",
      "[205] Augmented '44907' → D:\\Projects\\data\\augment1\\family\n",
      "[206] Augmented '44910' → D:\\Projects\\data\\augment1\\family\n",
      "[207] Augmented '44949' → D:\\Projects\\data\\augment1\\family\n",
      "[208] Augmented '45094' → D:\\Projects\\data\\augment1\\far\n",
      "[209] Augmented '45096' → D:\\Projects\\data\\augment1\\far\n",
      "[210] Augmented '45098' → D:\\Projects\\data\\augment1\\far\n",
      "[211] Augmented '45099' → D:\\Projects\\data\\augment1\\far\n",
      "[212] Augmented '45100' → D:\\Projects\\data\\augment1\\far\n",
      "[213] Augmented '45101' → D:\\Projects\\data\\augment1\\far\n",
      "[214] Augmented '45104' → D:\\Projects\\data\\augment1\\far\n",
      "[215] Augmented '45110' → D:\\Projects\\data\\augment1\\far\n",
      "[216] Augmented '45111' → D:\\Projects\\data\\augment1\\far\n",
      "[217] Augmented '45113' → D:\\Projects\\data\\augment1\\far\n",
      "[218] Augmented '45114' → D:\\Projects\\data\\augment1\\far\n",
      "[219] Augmented '45117' → D:\\Projects\\data\\augment1\\far\n",
      "[220] Augmented '45164' → D:\\Projects\\data\\augment1\\far\n",
      "[221] Augmented '45166' → D:\\Projects\\data\\augment1\\far\n",
      "[222] Augmented '45168' → D:\\Projects\\data\\augment1\\far\n",
      "[223] Augmented '45171' → D:\\Projects\\data\\augment1\\far\n",
      "[224] Augmented '45172' → D:\\Projects\\data\\augment1\\far\n",
      "[225] Augmented '45173' → D:\\Projects\\data\\augment1\\far\n",
      "[226] Augmented '45175' → D:\\Projects\\data\\augment1\\far\n",
      "[227] Augmented '45177' → D:\\Projects\\data\\augment1\\far\n",
      "[228] Augmented '46588' → D:\\Projects\\data\\augment1\\find\n",
      "[229] Augmented '46589' → D:\\Projects\\data\\augment1\\find\n",
      "[230] Augmented '46590' → D:\\Projects\\data\\augment1\\find\n",
      "[231] Augmented '46592' → D:\\Projects\\data\\augment1\\find\n",
      "[232] Augmented '46596' → D:\\Projects\\data\\augment1\\find\n",
      "[233] Augmented '46606' → D:\\Projects\\data\\augment1\\find\n",
      "[234] Augmented '46607' → D:\\Projects\\data\\augment1\\find\n",
      "[235] Augmented '46609' → D:\\Projects\\data\\augment1\\find\n",
      "[236] Augmented '46611' → D:\\Projects\\data\\augment1\\find\n",
      "[237] Augmented '46658' → D:\\Projects\\data\\augment1\\find\n",
      "[238] Augmented '46659' → D:\\Projects\\data\\augment1\\find\n",
      "[239] Augmented '46660' → D:\\Projects\\data\\augment1\\find\n",
      "[240] Augmented '46661' → D:\\Projects\\data\\augment1\\find\n",
      "[241] Augmented '46663' → D:\\Projects\\data\\augment1\\find\n",
      "[242] Augmented '51289' → D:\\Projects\\data\\augment1\\get\n",
      "[243] Augmented '51290' → D:\\Projects\\data\\augment1\\get\n",
      "[244] Augmented '51292' → D:\\Projects\\data\\augment1\\get\n",
      "[245] Augmented '51295' → D:\\Projects\\data\\augment1\\get\n",
      "[246] Augmented '51300' → D:\\Projects\\data\\augment1\\get\n",
      "[247] Augmented '51303' → D:\\Projects\\data\\augment1\\get\n",
      "[248] Augmented '51306' → D:\\Projects\\data\\augment1\\get\n",
      "[249] Augmented '51313' → D:\\Projects\\data\\augment1\\get\n",
      "[250] Augmented '51315' → D:\\Projects\\data\\augment1\\get\n",
      "[251] Augmented '51317' → D:\\Projects\\data\\augment1\\get\n",
      "[252] Augmented '51728' → D:\\Projects\\data\\augment1\\give\n",
      "[253] Augmented '51729' → D:\\Projects\\data\\augment1\\give\n",
      "[254] Augmented '51730' → D:\\Projects\\data\\augment1\\give\n",
      "[255] Augmented '51731' → D:\\Projects\\data\\augment1\\give\n",
      "[256] Augmented '51734' → D:\\Projects\\data\\augment1\\give\n",
      "[257] Augmented '51738' → D:\\Projects\\data\\augment1\\give\n",
      "[258] Augmented '51749' → D:\\Projects\\data\\augment1\\give\n",
      "[259] Augmented '51750' → D:\\Projects\\data\\augment1\\give\n",
      "[260] Augmented '51751' → D:\\Projects\\data\\augment1\\give\n",
      "[261] Augmented '51755' → D:\\Projects\\data\\augment1\\give\n",
      "[262] Augmented '51757' → D:\\Projects\\data\\augment1\\give\n",
      "[263] Augmented '51773' → D:\\Projects\\data\\augment1\\give\n",
      "[264] Augmented '51774' → D:\\Projects\\data\\augment1\\give\n",
      "[265] Augmented '51775' → D:\\Projects\\data\\augment1\\give\n",
      "[266] Augmented '51778' → D:\\Projects\\data\\augment1\\give\n",
      "[267] Augmented '51781' → D:\\Projects\\data\\augment1\\give\n",
      "[268] Augmented '51796' → D:\\Projects\\data\\augment1\\give\n",
      "[269] Augmented '51798' → D:\\Projects\\data\\augment1\\give\n",
      "[270] Augmented '52167' → D:\\Projects\\data\\augment1\\go\n",
      "[271] Augmented '52169' → D:\\Projects\\data\\augment1\\go\n",
      "[272] Augmented '52170' → D:\\Projects\\data\\augment1\\go\n",
      "[273] Augmented '52171' → D:\\Projects\\data\\augment1\\go\n",
      "[274] Augmented '52174' → D:\\Projects\\data\\augment1\\go\n",
      "[275] Augmented '52175' → D:\\Projects\\data\\augment1\\go\n",
      "[276] Augmented '52179' → D:\\Projects\\data\\augment1\\go\n",
      "[277] Augmented '52181' → D:\\Projects\\data\\augment1\\go\n",
      "[278] Augmented '52185' → D:\\Projects\\data\\augment1\\go\n",
      "[279] Augmented '52188' → D:\\Projects\\data\\augment1\\go\n",
      "[280] Augmented '52198' → D:\\Projects\\data\\augment1\\go\n",
      "[281] Augmented '52199' → D:\\Projects\\data\\augment1\\go\n",
      "[282] Augmented '52200' → D:\\Projects\\data\\augment1\\go\n",
      "[283] Augmented '52201' → D:\\Projects\\data\\augment1\\go\n",
      "[284] Augmented '52203' → D:\\Projects\\data\\augment1\\go\n",
      "[285] Augmented '52208' → D:\\Projects\\data\\augment1\\go\n",
      "[286] Augmented '52214' → D:\\Projects\\data\\augment1\\go\n",
      "[287] Augmented '52215' → D:\\Projects\\data\\augment1\\go\n",
      "[288] Augmented '52216' → D:\\Projects\\data\\augment1\\go\n",
      "[289] Augmented '52217' → D:\\Projects\\data\\augment1\\go\n",
      "[290] Augmented '52221' → D:\\Projects\\data\\augment1\\go\n",
      "[291] Augmented '52228' → D:\\Projects\\data\\augment1\\go\n",
      "[292] Augmented '52229' → D:\\Projects\\data\\augment1\\go\n",
      "[293] Augmented '52230' → D:\\Projects\\data\\augment1\\go\n",
      "[294] Augmented '52231' → D:\\Projects\\data\\augment1\\go\n",
      "[295] Augmented '52232' → D:\\Projects\\data\\augment1\\go\n",
      "[296] Augmented '52508' → D:\\Projects\\data\\augment1\\goodbye\n",
      "[297] Augmented '52509' → D:\\Projects\\data\\augment1\\goodbye\n",
      "[298] Augmented '52510' → D:\\Projects\\data\\augment1\\goodbye\n",
      "[299] Augmented '52512' → D:\\Projects\\data\\augment1\\goodbye\n",
      "[300] Augmented '52515' → D:\\Projects\\data\\augment1\\goodbye\n",
      "[301] Augmented '52551' → D:\\Projects\\data\\augment1\\goodbye\n",
      "[302] Augmented '52552' → D:\\Projects\\data\\augment1\\goodbye\n",
      "[303] Augmented '52554' → D:\\Projects\\data\\augment1\\goodbye\n",
      "[304] Augmented '52555' → D:\\Projects\\data\\augment1\\goodbye\n",
      "[305] Augmented '52556' → D:\\Projects\\data\\augment1\\goodbye\n",
      "[306] Augmented '52557' → D:\\Projects\\data\\augment1\\good\n",
      "[307] Augmented '52560' → D:\\Projects\\data\\augment1\\good\n",
      "[308] Augmented '52566' → D:\\Projects\\data\\augment1\\good\n",
      "[309] Augmented '52575' → D:\\Projects\\data\\augment1\\good\n",
      "[310] Augmented '52576' → D:\\Projects\\data\\augment1\\good\n",
      "[311] Augmented '52578' → D:\\Projects\\data\\augment1\\good\n",
      "[312] Augmented '52579' → D:\\Projects\\data\\augment1\\good\n",
      "[313] Augmented '52580' → D:\\Projects\\data\\augment1\\good\n",
      "[314] Augmented '52581' → D:\\Projects\\data\\augment1\\good\n",
      "[315] Augmented '52584' → D:\\Projects\\data\\augment1\\good\n",
      "[316] Augmented '52589' → D:\\Projects\\data\\augment1\\good\n",
      "[317] Augmented '52603' → D:\\Projects\\data\\augment1\\good\n",
      "[318] Augmented '52604' → D:\\Projects\\data\\augment1\\good\n",
      "[319] Augmented '52606' → D:\\Projects\\data\\augment1\\good\n",
      "[320] Augmented '52609' → D:\\Projects\\data\\augment1\\good\n",
      "[321] Augmented '52615' → D:\\Projects\\data\\augment1\\good\n",
      "[322] Augmented '56105' → D:\\Projects\\data\\augment1\\hello\n",
      "[323] Augmented '56106' → D:\\Projects\\data\\augment1\\hello\n",
      "[324] Augmented '56107' → D:\\Projects\\data\\augment1\\hello\n",
      "[325] Augmented '56108' → D:\\Projects\\data\\augment1\\hello\n",
      "[326] Augmented '56111' → D:\\Projects\\data\\augment1\\hello\n",
      "[327] Augmented '56114' → D:\\Projects\\data\\augment1\\hello\n",
      "[328] Augmented '56115' → D:\\Projects\\data\\augment1\\hello\n",
      "[329] Augmented '56117' → D:\\Projects\\data\\augment1\\hello\n",
      "[330] Augmented '56180' → D:\\Projects\\data\\augment1\\help\n",
      "[331] Augmented '56193' → D:\\Projects\\data\\augment1\\help\n",
      "[332] Augmented '56194' → D:\\Projects\\data\\augment1\\help\n",
      "[333] Augmented '56195' → D:\\Projects\\data\\augment1\\help\n",
      "[334] Augmented '56196' → D:\\Projects\\data\\augment1\\help\n",
      "[335] Augmented '56198' → D:\\Projects\\data\\augment1\\help\n",
      "[336] Augmented '56199' → D:\\Projects\\data\\augment1\\help\n",
      "[337] Augmented '56202' → D:\\Projects\\data\\augment1\\help\n",
      "[338] Augmented '56247' → D:\\Projects\\data\\augment1\\help\n",
      "[339] Augmented '56248' → D:\\Projects\\data\\augment1\\help\n",
      "[340] Augmented '56249' → D:\\Projects\\data\\augment1\\help\n",
      "[341] Augmented '56251' → D:\\Projects\\data\\augment1\\help\n",
      "[342] Augmented '56254' → D:\\Projects\\data\\augment1\\help\n",
      "[343] Augmented '56271' → D:\\Projects\\data\\augment1\\help\n",
      "[344] Augmented '56272' → D:\\Projects\\data\\augment1\\help\n",
      "[345] Augmented '56273' → D:\\Projects\\data\\augment1\\help\n",
      "[346] Augmented '56276' → D:\\Projects\\data\\augment1\\help\n",
      "[347] Augmented '56281' → D:\\Projects\\data\\augment1\\help\n",
      "[348] Augmented '56282' → D:\\Projects\\data\\augment1\\help\n",
      "[349] Augmented '56284' → D:\\Projects\\data\\augment1\\help\n",
      "[350] Augmented '63468' → D:\\Projects\\data\\augment1\\know\n",
      "[351] Augmented '63469' → D:\\Projects\\data\\augment1\\know\n",
      "[352] Augmented '63470' → D:\\Projects\\data\\augment1\\know\n",
      "[353] Augmented '63471' → D:\\Projects\\data\\augment1\\know\n",
      "[354] Augmented '63473' → D:\\Projects\\data\\augment1\\know\n",
      "[355] Augmented '63478' → D:\\Projects\\data\\augment1\\know\n",
      "[356] Augmented '63495' → D:\\Projects\\data\\augment1\\know\n",
      "[357] Augmented '63496' → D:\\Projects\\data\\augment1\\know\n",
      "[358] Augmented '63497' → D:\\Projects\\data\\augment1\\know\n",
      "[359] Augmented '63499' → D:\\Projects\\data\\augment1\\know\n",
      "[360] Augmented '63502' → D:\\Projects\\data\\augment1\\know\n",
      "[361] Augmented '63504' → D:\\Projects\\data\\augment1\\know\n",
      "[362] Augmented '63556' → D:\\Projects\\data\\augment1\\know\n",
      "[363] Augmented '63560' → D:\\Projects\\data\\augment1\\know\n",
      "[364] Augmented '65093' → D:\\Projects\\data\\augment1\\learn\n",
      "[365] Augmented '65094' → D:\\Projects\\data\\augment1\\learn\n",
      "[366] Augmented '65096' → D:\\Projects\\data\\augment1\\learn\n",
      "[367] Augmented '65097' → D:\\Projects\\data\\augment1\\learn\n",
      "[368] Augmented '65098' → D:\\Projects\\data\\augment1\\learn\n",
      "[369] Augmented '65100' → D:\\Projects\\data\\augment1\\learn\n",
      "[370] Augmented '65101' → D:\\Projects\\data\\augment1\\learn\n",
      "[371] Augmented '65107' → D:\\Projects\\data\\augment1\\learn\n",
      "[372] Augmented '65108' → D:\\Projects\\data\\augment1\\learn\n",
      "[373] Augmented '65110' → D:\\Projects\\data\\augment1\\learn\n",
      "[374] Augmented '65111' → D:\\Projects\\data\\augment1\\learn\n",
      "[375] Augmented '65113' → D:\\Projects\\data\\augment1\\learn\n",
      "[376] Augmented '65114' → D:\\Projects\\data\\augment1\\learn\n",
      "[377] Augmented '65438' → D:\\Projects\\data\\augment1\\like\n",
      "[378] Augmented '65439' → D:\\Projects\\data\\augment1\\like\n",
      "[379] Augmented '65440' → D:\\Projects\\data\\augment1\\like\n",
      "[380] Augmented '65442' → D:\\Projects\\data\\augment1\\like\n",
      "[381] Augmented '65443' → D:\\Projects\\data\\augment1\\like\n",
      "[382] Augmented '65444' → D:\\Projects\\data\\augment1\\like\n",
      "[383] Augmented '65445' → D:\\Projects\\data\\augment1\\like\n",
      "[384] Augmented '65449' → D:\\Projects\\data\\augment1\\like\n",
      "[385] Augmented '65450' → D:\\Projects\\data\\augment1\\like\n",
      "[386] Augmented '65451' → D:\\Projects\\data\\augment1\\like\n",
      "[387] Augmented '65453' → D:\\Projects\\data\\augment1\\like\n",
      "[388] Augmented '65454' → D:\\Projects\\data\\augment1\\like\n",
      "[389] Augmented '65457' → D:\\Projects\\data\\augment1\\like\n",
      "[390] Augmented '65458' → D:\\Projects\\data\\augment1\\like\n",
      "[391] Augmented '65460' → D:\\Projects\\data\\augment1\\like\n",
      "[392] Augmented '65461' → D:\\Projects\\data\\augment1\\like\n",
      "[393] Augmented '65462' → D:\\Projects\\data\\augment1\\like\n",
      "[394] Augmented '65464' → D:\\Projects\\data\\augment1\\like\n",
      "[395] Augmented '65888' → D:\\Projects\\data\\augment1\\love\n",
      "[396] Augmented '65889' → D:\\Projects\\data\\augment1\\love\n",
      "[397] Augmented '65890' → D:\\Projects\\data\\augment1\\love\n",
      "[398] Augmented '65891' → D:\\Projects\\data\\augment1\\love\n",
      "[399] Augmented '65892' → D:\\Projects\\data\\augment1\\love\n",
      "[400] Augmented '65893' → D:\\Projects\\data\\augment1\\love\n",
      "[401] Augmented '65894' → D:\\Projects\\data\\augment1\\love\n",
      "[402] Augmented '65895' → D:\\Projects\\data\\augment1\\love\n",
      "[403] Augmented '65898' → D:\\Projects\\data\\augment1\\love\n",
      "[404] Augmented '65899' → D:\\Projects\\data\\augment1\\love\n",
      "[405] Augmented '65905' → D:\\Projects\\data\\augment1\\love\n",
      "[406] Augmented '65909' → D:\\Projects\\data\\augment1\\love\n",
      "[407] Augmented '65912' → D:\\Projects\\data\\augment1\\love\n",
      "[408] Augmented '65913' → D:\\Projects\\data\\augment1\\love\n",
      "[409] Augmented '66054' → D:\\Projects\\data\\augment1\\make\n",
      "[410] Augmented '66055' → D:\\Projects\\data\\augment1\\make\n",
      "[411] Augmented '66056' → D:\\Projects\\data\\augment1\\make\n",
      "[412] Augmented '66057' → D:\\Projects\\data\\augment1\\make\n",
      "[413] Augmented '66058' → D:\\Projects\\data\\augment1\\make\n",
      "[414] Augmented '66059' → D:\\Projects\\data\\augment1\\make\n",
      "[415] Augmented '66060' → D:\\Projects\\data\\augment1\\make\n",
      "[416] Augmented '66061' → D:\\Projects\\data\\augment1\\make\n",
      "[417] Augmented '66065' → D:\\Projects\\data\\augment1\\make\n",
      "[418] Augmented '66067' → D:\\Projects\\data\\augment1\\make\n",
      "[419] Augmented '66068' → D:\\Projects\\data\\augment1\\make\n",
      "[420] Augmented '66069' → D:\\Projects\\data\\augment1\\make\n",
      "[421] Augmented '66072' → D:\\Projects\\data\\augment1\\make\n",
      "[422] Augmented '66073' → D:\\Projects\\data\\augment1\\make\n",
      "[423] Augmented '66075' → D:\\Projects\\data\\augment1\\make\n",
      "[424] Augmented '66078' → D:\\Projects\\data\\augment1\\make\n",
      "[425] Augmented '66079' → D:\\Projects\\data\\augment1\\make\n",
      "[426] Augmented '66080' → D:\\Projects\\data\\augment1\\make\n",
      "Done: 426/444 videos in 433.34s\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Video Augmentation for TOP-30 (New Pipeline)\n",
    "import os\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ——— PARAMETERS from Cell 1 ———\n",
    "# DATA_ROOT, TOP30, AUG_DIR were already defined in Cell 1\n",
    "# filtered_csv was set to os.path.join(DATA_ROOT, 'filtered_top30.csv')\n",
    "NUM_AUG = 3   # how many augmentations per original\n",
    "\n",
    "# Load filtered CSV\n",
    "df_aug = pd.read_csv(os.path.join(DATA_ROOT, 'filtered_top30.csv'))\n",
    "\n",
    "# Simple augmentation: flip + small rotation\n",
    "def simple_augment(frames, num_aug):\n",
    "    h, w = frames[0].shape[:2]\n",
    "    aug_sets = []\n",
    "    for _ in range(num_aug):\n",
    "        out = []\n",
    "        for f in frames:\n",
    "            # horizontal flip 50%\n",
    "            if np.random.rand() < 0.5:\n",
    "                f2 = cv2.flip(f, 1)\n",
    "            else:\n",
    "                f2 = f.copy()\n",
    "            # random rotation ±10°\n",
    "            ang = np.random.uniform(-10, 10)\n",
    "            M   = cv2.getRotationMatrix2D((w/2, h/2), ang, 1)\n",
    "            f2  = cv2.warpAffine(f2, M, (w, h))\n",
    "            out.append(f2)\n",
    "        aug_sets.append(out)\n",
    "    return aug_sets\n",
    "\n",
    "# Make sure AUG_DIR exists\n",
    "os.makedirs(AUG_DIR, exist_ok=True)\n",
    "\n",
    "t0 = time.time()\n",
    "count = 0\n",
    "\n",
    "for _, row in df_aug.iterrows():\n",
    "    src = row['Filepath']\n",
    "    lbl = row['Label']\n",
    "    if not os.path.exists(src):\n",
    "        print(f\"Missing source video: {src}\")\n",
    "        continue\n",
    "\n",
    "    # Read all frames into a list\n",
    "    cap    = cv2.VideoCapture(src)\n",
    "    frames = []\n",
    "    while True:\n",
    "        ret, fr = cap.read()\n",
    "        if not ret: break\n",
    "        frames.append(fr)\n",
    "    cap.release()\n",
    "    if not frames:\n",
    "        continue\n",
    "\n",
    "    # Prepare per-label folder under AUG_DIR\n",
    "    out_dir = os.path.join(AUG_DIR, lbl)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    base = Path(src).stem\n",
    "\n",
    "    # Write the original (renamed) into augment1/Label/\n",
    "    fourcc    = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    fps       = 30  # or cap.get(cv2.CAP_PROP_FPS)\n",
    "    h, w      = frames[0].shape[:2]\n",
    "    orig_out  = os.path.join(out_dir, f\"{base}_orig.mp4\")\n",
    "    writer = cv2.VideoWriter(orig_out, fourcc, fps, (w, h))\n",
    "    for f in frames:\n",
    "        writer.write(f)\n",
    "    writer.release()\n",
    "\n",
    "    # Create & save augmented clips\n",
    "    aug_lists = simple_augment(frames, NUM_AUG)\n",
    "    for i, aug in enumerate(aug_lists):\n",
    "        aug_path = os.path.join(out_dir, f\"{base}_aug{i}.mp4\")\n",
    "        writer   = cv2.VideoWriter(aug_path, fourcc, fps, (w, h))\n",
    "        for fr in aug:\n",
    "            writer.write(fr)\n",
    "        writer.release()\n",
    "\n",
    "    count += 1\n",
    "    print(f\"[{count:03d}] Augmented '{base}' → {out_dir}\")\n",
    "\n",
    "print(f\"Done: {count}/{len(df_aug)} videos in {time.time()-t0:.2f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f3af3b1-3d95-4823-815c-282484c12826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 16 frames → 138 features/frame → 2208 total\n",
      "✅ Extracted 1704 sequences in 2043.95s → D:\\Projects\\data\\landmark1\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Extract & Save Hand+Pose Landmarks for All Augmented Videos\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mediapipe as mp\n",
    "\n",
    "# ——— CONSTANTS for Frame & Feature Dimensions ———\n",
    "NUM_FRAMES        = 16                             # fixed timesteps per clip\n",
    "POSE_IDX          = [11, 12, 13, 14]               # shoulders & elbows\n",
    "HAND_LM_COUNT     = 21                             # MediaPipe hand keypoints\n",
    "H_FEATS_PER_HAND  = HAND_LM_COUNT * 3              # x,y,z per hand point\n",
    "P_FEATS           = len(POSE_IDX) * 3              # x,y,z per pose point\n",
    "FEATURE_PER_FRAME = H_FEATS_PER_HAND * 2 + P_FEATS  # features in one frame\n",
    "TOTAL_FEATURES    = NUM_FRAMES * FEATURE_PER_FRAME  # total input dims\n",
    "\n",
    "print(f\"Sampling {NUM_FRAMES} frames → {FEATURE_PER_FRAME} features/frame → {TOTAL_FEATURES} total\")\n",
    "\n",
    "# ——— PARAMS & PATHS from Cell 1 & 2 ———\n",
    "filtered_csv = os.path.join(DATA_ROOT, 'filtered_top30.csv')\n",
    "df           = pd.read_csv(filtered_csv)\n",
    "SEQ_LEN      = NUM_FRAMES\n",
    "AUG_DIR      = os.path.join(DATA_ROOT, 'augment1')\n",
    "LANDMARK_DIR = os.path.join(DATA_ROOT, 'landmark1')\n",
    "TOP30        = df['Label'].unique().tolist()\n",
    "\n",
    "# ——— MediaPipe Setup ———\n",
    "mp_hands = mp.solutions.hands.Hands(\n",
    "    static_image_mode=False,\n",
    "    max_num_hands=2,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "mp_pose  = mp.solutions.pose.Pose(\n",
    "    static_image_mode=False,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "def normalize_hand_landmarks(arr21x3):\n",
    "    \"\"\"Subtract wrist, scale so max distance=1, then flatten.\"\"\"\n",
    "    wrist = arr21x3[0]\n",
    "    rel   = arr21x3 - wrist\n",
    "    norm  = np.linalg.norm(rel, axis=1).max() or 1.0\n",
    "    return (rel / norm).reshape(-1)\n",
    "\n",
    "def extract_landmarks(video_fp, out_root, label):\n",
    "    cap   = cv2.VideoCapture(video_fp)\n",
    "    total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    if total <= 0:\n",
    "        cap.release()\n",
    "        return False\n",
    "\n",
    "    # uniformly sample NUM_FRAMES indices\n",
    "    idxs = np.linspace(0, total-1, SEQ_LEN, dtype=int)\n",
    "    seq  = []\n",
    "\n",
    "    for i in idxs:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, int(i))\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "\n",
    "        img       = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        feats_row = []\n",
    "\n",
    "        # — Hands —\n",
    "        res_h = mp_hands.process(img)\n",
    "        hand_feats = []\n",
    "        if res_h.multi_hand_landmarks:\n",
    "            hands_handed = list(zip(res_h.multi_hand_landmarks, res_h.multi_handedness))\n",
    "            hands_handed.sort(key=lambda x: x[1].classification[0].label)\n",
    "            for lm, _ in hands_handed[:2]:\n",
    "                arr = np.array([[p.x, p.y, p.z] for p in lm.landmark], dtype=np.float32)\n",
    "                hand_feats.extend(normalize_hand_landmarks(arr))\n",
    "        # pad to always have two hands\n",
    "        while len(hand_feats) < H_FEATS_PER_HAND * 2:\n",
    "            hand_feats.extend([0.0] * H_FEATS_PER_HAND)\n",
    "        feats_row.extend(hand_feats)\n",
    "\n",
    "        # — Pose —\n",
    "        res_p = mp_pose.process(img)\n",
    "        pose_feats = []\n",
    "        if res_p.pose_landmarks:\n",
    "            for pi in POSE_IDX:\n",
    "                p = res_p.pose_landmarks.landmark[pi]\n",
    "                pose_feats.extend([p.x, p.y, p.z])\n",
    "        # pad pose features\n",
    "        while len(pose_feats) < P_FEATS:\n",
    "            pose_feats.extend([0.0, 0.0, 0.0])\n",
    "        feats_row.extend(pose_feats)\n",
    "\n",
    "        seq.append(feats_row)\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    # pad sequence if too short\n",
    "    if len(seq) < SEQ_LEN:\n",
    "        pad = seq[-1] if seq else [0.0] * FEATURE_PER_FRAME\n",
    "        seq.extend([pad] * (SEQ_LEN - len(seq)))\n",
    "\n",
    "    arr = np.array(seq, dtype=np.float32)  # shape: (NUM_FRAMES, FEATURE_PER_FRAME)\n",
    "\n",
    "    # save under landmark1/<label>/\n",
    "    out_dir = os.path.join(LANDMARK_DIR, label)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    fname = os.path.splitext(os.path.basename(video_fp))[0] + \".npy\"\n",
    "    np.save(os.path.join(out_dir, fname), arr)\n",
    "    return True\n",
    "\n",
    "# ——— Run extraction over all augmented videos ———\n",
    "t0, cnt = time.time(), 0\n",
    "for label in TOP30:\n",
    "    for vid_fp in glob.glob(os.path.join(AUG_DIR, label, \"*.mp4\")):\n",
    "        if extract_landmarks(vid_fp, LANDMARK_DIR, label):\n",
    "            cnt += 1\n",
    "\n",
    "mp_hands.close()\n",
    "mp_pose.close()\n",
    "print(f\"✅ Extracted {cnt} sequences in {time.time()-t0:.2f}s → {LANDMARK_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f46162e2-4b5c-4e58-b92a-a42c8ddeb4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Built dataset → X.shape = (2981, 16, 69), y.shape = (2981,)\n"
     ]
    }
   ],
   "source": [
    "# ─── Cell 4: Feature Extraction → X (N,16,69), y (N,) ─────────────────\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "# ——— PARAMETERS ———\n",
    "DATA_ROOT    = r\"D:\\Projects\\data\"               # from Cell 1\n",
    "LANDMARK_DIR = os.path.join(DATA_ROOT, 'landmark1')\n",
    "NUM_FRAMES   = 16\n",
    "\n",
    "# finger chains for joint‐angle calculations\n",
    "FINGERS = [\n",
    "    [1,2,3,4],    # thumb\n",
    "    [5,6,7,8],    # index\n",
    "    [9,10,11,12], # middle\n",
    "    [13,14,15,16],# ring\n",
    "    [17,18,19,20] # pinky\n",
    "]\n",
    "\n",
    "# ── Helpers ──\n",
    "def preprocess_sequence(lm_seq):\n",
    "    # Drop all-zero frames, then downsample or pad to NUM_FRAMES\n",
    "    mask = ~np.all(np.isclose(lm_seq, 0, atol=1e-6), axis=1)\n",
    "    seq  = lm_seq[mask]\n",
    "    if len(seq) > NUM_FRAMES:\n",
    "        idxs = np.linspace(0, len(seq)-1, NUM_FRAMES, dtype=int)\n",
    "        seq  = seq[idxs]\n",
    "    if len(seq) < NUM_FRAMES:\n",
    "        pad = np.zeros((NUM_FRAMES - len(seq), lm_seq.shape[1]), dtype=np.float32)\n",
    "        seq = np.vstack([pad, seq])\n",
    "    return seq  # (NUM_FRAMES, 138)\n",
    "\n",
    "def compute_frame_features(frame):\n",
    "    # frame: (138,) = 2 hands×21×3 + 4 pose pts×3\n",
    "    hands = frame[:126].reshape(2,21,3)\n",
    "    pose  = frame[126:].reshape(4,3)\n",
    "    l_sh, r_sh, l_el, r_el = pose\n",
    "    angles = []\n",
    "    # 1) hand joint‐angles\n",
    "    for hand in hands:\n",
    "        pw     = np.linalg.norm(hand[5] - hand[17]) or 1.0\n",
    "        coords = (hand - hand[0]) / pw\n",
    "        for chain in FINGERS:\n",
    "            for i,j,k in zip(chain, chain[1:], chain[2:]):\n",
    "                v1   = coords[i] - coords[j]\n",
    "                v2   = coords[k] - coords[j]\n",
    "                cosθ = np.dot(v1,v2)/(np.linalg.norm(v1)*np.linalg.norm(v2)+1e-6)\n",
    "                angles.append(np.arccos(np.clip(cosθ,-1,1)))\n",
    "    # 2) elbow angles\n",
    "    def angle(a,b,c):\n",
    "        v1   = a - b; v2 = c - b\n",
    "        cosθ = np.dot(v1,v2)/(np.linalg.norm(v1)*np.linalg.norm(v2)+1e-6)\n",
    "        return np.arccos(np.clip(cosθ,-1,1))\n",
    "    lw, rw = hands[0,0], hands[1,0]\n",
    "    e_left  = angle(l_sh, l_el, lw)\n",
    "    e_right = angle(r_sh, r_el, rw)\n",
    "    # 3) inter-wrist distance\n",
    "    dist_w  = np.linalg.norm(lw - rw)\n",
    "\n",
    "    return np.array(angles + [e_left, e_right, dist_w], dtype=np.float32)  # (23,)\n",
    "\n",
    "def interpolate_missing(seq):\n",
    "    # fill tiny zero‐gaps per dimension\n",
    "    for d in range(seq.shape[1]):\n",
    "        col   = seq[:,d]\n",
    "        miss  = np.isclose(col, 0, atol=1e-6)\n",
    "        valid = ~miss\n",
    "        if miss.any() and valid.any():\n",
    "            seq[miss,d] = np.interp(np.where(miss)[0], np.where(valid)[0], col[valid])\n",
    "    return seq\n",
    "\n",
    "def compute_dynamic_features(lm_seq):\n",
    "    # preprocess → static 23 dims/frame + vel + acc → 69 dims/frame\n",
    "    seq    = preprocess_sequence(lm_seq)                             # (16,138)\n",
    "    static = np.stack([compute_frame_features(f) for f in seq], axis=0)  # (16,23)\n",
    "    static = interpolate_missing(static)\n",
    "    vel    = np.diff(static, axis=0, prepend=static[0:1])            # (16,23)\n",
    "    acc    = np.diff(vel,    axis=0, prepend=vel[0:1])               # (16,23)\n",
    "    return np.concatenate([static, vel, acc], axis=1)                # (16,69)\n",
    "\n",
    "# ─── Build X, y ──────────────────────────────────────────────────────────\n",
    "classes = sorted(d for d in os.listdir(LANDMARK_DIR)\n",
    "                 if os.path.isdir(os.path.join(LANDMARK_DIR, d)))\n",
    "label_map = {lab:i for i, lab in enumerate(classes)}\n",
    "\n",
    "X, y = [], []\n",
    "for lab in classes:\n",
    "    for fp in glob.glob(os.path.join(LANDMARK_DIR, lab, '*.npy')):\n",
    "        seq   = np.load(fp)                    # (T,138)\n",
    "        feats = compute_dynamic_features(seq)  # (16,69)\n",
    "        X.append(feats)                        # keep 2D\n",
    "        y.append(label_map[lab])\n",
    "\n",
    "X = np.stack(X, axis=0)                       # → (N,16,69)\n",
    "y = np.array(y, dtype='int32')                # → (N,)\n",
    "\n",
    "print(f\"✅ Built dataset → X.shape = {X.shape}, y.shape = {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32709ffc-0f4a-4f00-98c5-f424b7261f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Projects\\signify-ml\\lib\\site-packages\\keras\\src\\layers\\layer.py:965: UserWarning: Layer 'conv1d' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Projects\\signify-ml\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"ASL_TCN_LSTM\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"ASL_TCN_LSTM\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_seq (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">69</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ masking (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">69</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_seq[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">13,312</span> │ masking[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],             │\n",
       "│                               │                           │                 │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                  │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">197,632</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ bidirectional_1               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">164,352</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)               │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ simple_attention              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │             <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleAttention</span>)             │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ simple_attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,885</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_seq (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m69\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ masking (\u001b[38;5;33mMasking\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m69\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ input_seq[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m13,312\u001b[0m │ masking[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m256\u001b[0m │ conv1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ batch_normalization[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m12,352\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m256\u001b[0m │ conv1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add (\u001b[38;5;33mAdd\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],             │\n",
       "│                               │                           │                 │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m12,352\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                  │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m256\u001b[0m │ conv1d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │         \u001b[38;5;34m197,632\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │ bidirectional[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ bidirectional_1               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │         \u001b[38;5;34m164,352\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)               │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │ bidirectional_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ simple_attention              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │             \u001b[38;5;34m144\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mSimpleAttention\u001b[0m)             │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m8,256\u001b[0m │ simple_attention[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │             \u001b[38;5;34m128\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ layer_normalization[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)                │           \u001b[38;5;34m1,885\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">411,181</span> (1.57 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m411,181\u001b[0m (1.57 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">410,797</span> (1.57 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m410,797\u001b[0m (1.57 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Projects\\signify-ml\\lib\\site-packages\\keras\\src\\layers\\layer.py:965: UserWarning: Layer 'conv1d' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 - 16s - 417ms/step - accuracy: 0.0398 - loss: 4.0334 - val_accuracy: 0.0251 - val_loss: 3.8826 - learning_rate: 1.0000e-03\n",
      "Epoch 2/100\n",
      "38/38 - 2s - 62ms/step - accuracy: 0.0587 - loss: 3.6285 - val_accuracy: 0.0251 - val_loss: 3.7395 - learning_rate: 1.0000e-03\n",
      "Epoch 3/100\n",
      "38/38 - 2s - 63ms/step - accuracy: 0.0721 - loss: 3.4579 - val_accuracy: 0.0335 - val_loss: 3.6505 - learning_rate: 1.0000e-03\n",
      "Epoch 4/100\n",
      "38/38 - 2s - 66ms/step - accuracy: 0.0826 - loss: 3.3292 - val_accuracy: 0.0452 - val_loss: 3.4442 - learning_rate: 1.0000e-03\n",
      "Epoch 5/100\n",
      "38/38 - 2s - 61ms/step - accuracy: 0.0826 - loss: 3.2861 - val_accuracy: 0.0938 - val_loss: 3.1313 - learning_rate: 1.0000e-03\n",
      "Epoch 6/100\n",
      "38/38 - 2s - 62ms/step - accuracy: 0.1204 - loss: 3.1531 - val_accuracy: 0.1441 - val_loss: 3.0211 - learning_rate: 1.0000e-03\n",
      "Epoch 7/100\n",
      "38/38 - 2s - 60ms/step - accuracy: 0.1242 - loss: 3.0768 - val_accuracy: 0.1943 - val_loss: 2.9177 - learning_rate: 1.0000e-03\n",
      "Epoch 8/100\n",
      "38/38 - 2s - 62ms/step - accuracy: 0.1472 - loss: 2.9843 - val_accuracy: 0.1977 - val_loss: 2.8643 - learning_rate: 1.0000e-03\n",
      "Epoch 9/100\n",
      "38/38 - 2s - 60ms/step - accuracy: 0.1678 - loss: 2.8975 - val_accuracy: 0.1709 - val_loss: 2.9962 - learning_rate: 1.0000e-03\n",
      "Epoch 10/100\n",
      "38/38 - 2s - 60ms/step - accuracy: 0.1816 - loss: 2.8452 - val_accuracy: 0.2178 - val_loss: 2.7879 - learning_rate: 1.0000e-03\n",
      "Epoch 11/100\n",
      "38/38 - 2s - 63ms/step - accuracy: 0.1875 - loss: 2.7715 - val_accuracy: 0.1575 - val_loss: 2.8957 - learning_rate: 1.0000e-03\n",
      "Epoch 12/100\n",
      "38/38 - 3s - 67ms/step - accuracy: 0.1980 - loss: 2.7350 - val_accuracy: 0.2161 - val_loss: 2.8166 - learning_rate: 1.0000e-03\n",
      "Epoch 13/100\n",
      "38/38 - 3s - 71ms/step - accuracy: 0.2278 - loss: 2.6190 - val_accuracy: 0.1625 - val_loss: 2.9469 - learning_rate: 1.0000e-03\n",
      "Epoch 14/100\n",
      "38/38 - 2s - 60ms/step - accuracy: 0.2253 - loss: 2.5913 - val_accuracy: 0.2395 - val_loss: 2.6644 - learning_rate: 1.0000e-03\n",
      "Epoch 15/100\n",
      "38/38 - 2s - 59ms/step - accuracy: 0.2408 - loss: 2.5391 - val_accuracy: 0.2412 - val_loss: 2.5705 - learning_rate: 1.0000e-03\n",
      "Epoch 16/100\n",
      "38/38 - 2s - 58ms/step - accuracy: 0.2689 - loss: 2.4682 - val_accuracy: 0.1658 - val_loss: 3.0238 - learning_rate: 1.0000e-03\n",
      "Epoch 17/100\n",
      "38/38 - 2s - 61ms/step - accuracy: 0.2689 - loss: 2.3991 - val_accuracy: 0.2781 - val_loss: 2.5616 - learning_rate: 1.0000e-03\n",
      "Epoch 18/100\n",
      "38/38 - 2s - 58ms/step - accuracy: 0.2768 - loss: 2.3683 - val_accuracy: 0.2613 - val_loss: 2.5356 - learning_rate: 1.0000e-03\n",
      "Epoch 19/100\n",
      "38/38 - 2s - 59ms/step - accuracy: 0.2957 - loss: 2.3082 - val_accuracy: 0.2596 - val_loss: 2.6438 - learning_rate: 1.0000e-03\n",
      "Epoch 20/100\n",
      "38/38 - 2s - 58ms/step - accuracy: 0.2991 - loss: 2.2828 - val_accuracy: 0.2529 - val_loss: 2.6144 - learning_rate: 1.0000e-03\n",
      "Epoch 21/100\n",
      "38/38 - 2s - 58ms/step - accuracy: 0.3196 - loss: 2.2010 - val_accuracy: 0.2580 - val_loss: 2.5646 - learning_rate: 1.0000e-03\n",
      "Epoch 22/100\n",
      "38/38 - 2s - 57ms/step - accuracy: 0.3289 - loss: 2.1753 - val_accuracy: 0.3400 - val_loss: 2.2097 - learning_rate: 1.0000e-03\n",
      "Epoch 23/100\n",
      "38/38 - 2s - 57ms/step - accuracy: 0.3603 - loss: 2.0977 - val_accuracy: 0.3668 - val_loss: 2.1483 - learning_rate: 1.0000e-03\n",
      "Epoch 24/100\n",
      "38/38 - 2s - 57ms/step - accuracy: 0.3691 - loss: 2.0756 - val_accuracy: 0.3400 - val_loss: 2.2516 - learning_rate: 1.0000e-03\n",
      "Epoch 25/100\n",
      "38/38 - 2s - 59ms/step - accuracy: 0.3716 - loss: 2.0197 - val_accuracy: 0.4472 - val_loss: 1.9989 - learning_rate: 1.0000e-03\n",
      "Epoch 26/100\n",
      "38/38 - 2s - 58ms/step - accuracy: 0.3817 - loss: 1.9735 - val_accuracy: 0.3467 - val_loss: 2.1921 - learning_rate: 1.0000e-03\n",
      "Epoch 27/100\n",
      "38/38 - 2s - 58ms/step - accuracy: 0.4002 - loss: 1.9367 - val_accuracy: 0.2915 - val_loss: 2.5211 - learning_rate: 1.0000e-03\n",
      "Epoch 28/100\n",
      "38/38 - 2s - 58ms/step - accuracy: 0.3964 - loss: 1.9059 - val_accuracy: 0.1993 - val_loss: 3.1517 - learning_rate: 1.0000e-03\n",
      "Epoch 29/100\n",
      "38/38 - 2s - 60ms/step - accuracy: 0.4312 - loss: 1.8666 - val_accuracy: 0.4640 - val_loss: 1.8788 - learning_rate: 1.0000e-03\n",
      "Epoch 30/100\n",
      "38/38 - 2s - 59ms/step - accuracy: 0.4417 - loss: 1.8518 - val_accuracy: 0.3484 - val_loss: 2.2431 - learning_rate: 1.0000e-03\n",
      "Epoch 31/100\n",
      "38/38 - 2s - 59ms/step - accuracy: 0.4383 - loss: 1.7813 - val_accuracy: 0.4573 - val_loss: 1.9145 - learning_rate: 1.0000e-03\n",
      "Epoch 32/100\n",
      "38/38 - 2s - 56ms/step - accuracy: 0.4530 - loss: 1.7755 - val_accuracy: 0.4623 - val_loss: 1.9856 - learning_rate: 1.0000e-03\n",
      "Epoch 33/100\n",
      "38/38 - 2s - 57ms/step - accuracy: 0.4492 - loss: 1.7377 - val_accuracy: 0.3903 - val_loss: 2.0624 - learning_rate: 1.0000e-03\n",
      "Epoch 34/100\n",
      "38/38 - 2s - 58ms/step - accuracy: 0.4878 - loss: 1.6893 - val_accuracy: 0.4405 - val_loss: 2.0103 - learning_rate: 1.0000e-03\n",
      "Epoch 35/100\n",
      "38/38 - 2s - 57ms/step - accuracy: 0.4945 - loss: 1.6292 - val_accuracy: 0.5209 - val_loss: 1.6725 - learning_rate: 5.0000e-04\n",
      "Epoch 36/100\n",
      "38/38 - 2s - 57ms/step - accuracy: 0.5155 - loss: 1.5739 - val_accuracy: 0.5243 - val_loss: 1.7478 - learning_rate: 5.0000e-04\n",
      "Epoch 37/100\n",
      "38/38 - 2s - 57ms/step - accuracy: 0.5147 - loss: 1.5652 - val_accuracy: 0.4724 - val_loss: 1.8991 - learning_rate: 5.0000e-04\n",
      "Epoch 38/100\n",
      "38/38 - 2s - 59ms/step - accuracy: 0.5260 - loss: 1.5249 - val_accuracy: 0.5008 - val_loss: 1.7748 - learning_rate: 5.0000e-04\n",
      "Epoch 39/100\n",
      "38/38 - 2s - 59ms/step - accuracy: 0.5285 - loss: 1.4782 - val_accuracy: 0.5796 - val_loss: 1.5370 - learning_rate: 5.0000e-04\n",
      "Epoch 40/100\n",
      "38/38 - 2s - 58ms/step - accuracy: 0.5369 - loss: 1.4818 - val_accuracy: 0.4791 - val_loss: 1.8226 - learning_rate: 5.0000e-04\n",
      "Epoch 41/100\n",
      "38/38 - 2s - 58ms/step - accuracy: 0.5323 - loss: 1.4659 - val_accuracy: 0.5695 - val_loss: 1.6307 - learning_rate: 5.0000e-04\n",
      "Epoch 42/100\n",
      "38/38 - 2s - 58ms/step - accuracy: 0.5608 - loss: 1.4294 - val_accuracy: 0.5997 - val_loss: 1.4722 - learning_rate: 5.0000e-04\n",
      "Epoch 43/100\n",
      "38/38 - 2s - 57ms/step - accuracy: 0.5537 - loss: 1.4259 - val_accuracy: 0.5511 - val_loss: 1.6431 - learning_rate: 5.0000e-04\n",
      "Epoch 44/100\n",
      "38/38 - 2s - 58ms/step - accuracy: 0.5633 - loss: 1.3898 - val_accuracy: 0.6064 - val_loss: 1.4499 - learning_rate: 5.0000e-04\n",
      "Epoch 45/100\n",
      "38/38 - 2s - 57ms/step - accuracy: 0.5730 - loss: 1.3767 - val_accuracy: 0.5427 - val_loss: 1.6039 - learning_rate: 5.0000e-04\n",
      "Epoch 46/100\n",
      "38/38 - 2s - 56ms/step - accuracy: 0.5868 - loss: 1.3591 - val_accuracy: 0.5695 - val_loss: 1.5993 - learning_rate: 5.0000e-04\n",
      "Epoch 47/100\n",
      "38/38 - 2s - 58ms/step - accuracy: 0.5763 - loss: 1.3326 - val_accuracy: 0.5946 - val_loss: 1.5280 - learning_rate: 5.0000e-04\n",
      "Epoch 48/100\n",
      "38/38 - 2s - 59ms/step - accuracy: 0.5919 - loss: 1.3084 - val_accuracy: 0.6315 - val_loss: 1.3684 - learning_rate: 5.0000e-04\n",
      "Epoch 49/100\n",
      "38/38 - 2s - 57ms/step - accuracy: 0.6074 - loss: 1.2778 - val_accuracy: 0.6064 - val_loss: 1.4341 - learning_rate: 5.0000e-04\n",
      "Epoch 50/100\n",
      "38/38 - 2s - 57ms/step - accuracy: 0.5885 - loss: 1.3016 - val_accuracy: 0.5779 - val_loss: 1.4932 - learning_rate: 5.0000e-04\n",
      "Epoch 51/100\n",
      "38/38 - 2s - 57ms/step - accuracy: 0.5986 - loss: 1.2691 - val_accuracy: 0.6214 - val_loss: 1.4051 - learning_rate: 5.0000e-04\n",
      "Epoch 52/100\n",
      "38/38 - 2s - 57ms/step - accuracy: 0.6275 - loss: 1.2182 - val_accuracy: 0.6667 - val_loss: 1.3123 - learning_rate: 5.0000e-04\n",
      "Epoch 53/100\n",
      "38/38 - 2s - 58ms/step - accuracy: 0.6174 - loss: 1.2420 - val_accuracy: 0.6466 - val_loss: 1.3004 - learning_rate: 5.0000e-04\n",
      "Epoch 54/100\n",
      "38/38 - 2s - 57ms/step - accuracy: 0.6154 - loss: 1.2600 - val_accuracy: 0.6399 - val_loss: 1.4084 - learning_rate: 5.0000e-04\n",
      "Epoch 55/100\n",
      "38/38 - 2s - 57ms/step - accuracy: 0.6078 - loss: 1.2551 - val_accuracy: 0.6332 - val_loss: 1.3234 - learning_rate: 5.0000e-04\n",
      "Epoch 56/100\n",
      "38/38 - 2s - 58ms/step - accuracy: 0.6317 - loss: 1.1695 - val_accuracy: 0.6549 - val_loss: 1.2830 - learning_rate: 5.0000e-04\n",
      "Epoch 57/100\n",
      "38/38 - 2s - 58ms/step - accuracy: 0.6342 - loss: 1.1789 - val_accuracy: 0.5980 - val_loss: 1.4729 - learning_rate: 5.0000e-04\n",
      "Epoch 58/100\n",
      "38/38 - 2s - 57ms/step - accuracy: 0.6380 - loss: 1.1709 - val_accuracy: 0.6432 - val_loss: 1.3107 - learning_rate: 5.0000e-04\n",
      "Epoch 59/100\n",
      "38/38 - 2s - 57ms/step - accuracy: 0.6510 - loss: 1.1324 - val_accuracy: 0.6834 - val_loss: 1.2190 - learning_rate: 5.0000e-04\n",
      "Epoch 60/100\n",
      "38/38 - 2s - 57ms/step - accuracy: 0.6594 - loss: 1.1267 - val_accuracy: 0.6700 - val_loss: 1.2648 - learning_rate: 5.0000e-04\n",
      "Epoch 61/100\n",
      "38/38 - 2s - 57ms/step - accuracy: 0.6577 - loss: 1.0908 - val_accuracy: 0.6767 - val_loss: 1.1942 - learning_rate: 5.0000e-04\n",
      "Epoch 62/100\n",
      "38/38 - 2s - 57ms/step - accuracy: 0.6594 - loss: 1.1213 - val_accuracy: 0.6181 - val_loss: 1.4077 - learning_rate: 5.0000e-04\n",
      "Epoch 63/100\n",
      "38/38 - 2s - 58ms/step - accuracy: 0.6648 - loss: 1.0914 - val_accuracy: 0.6951 - val_loss: 1.1960 - learning_rate: 5.0000e-04\n",
      "Epoch 64/100\n",
      "38/38 - 2s - 57ms/step - accuracy: 0.6594 - loss: 1.1150 - val_accuracy: 0.6884 - val_loss: 1.2355 - learning_rate: 5.0000e-04\n",
      "Epoch 65/100\n",
      "38/38 - 2s - 56ms/step - accuracy: 0.6690 - loss: 1.0926 - val_accuracy: 0.6533 - val_loss: 1.3080 - learning_rate: 5.0000e-04\n",
      "Epoch 66/100\n",
      "38/38 - 2s - 57ms/step - accuracy: 0.6741 - loss: 1.0570 - val_accuracy: 0.6901 - val_loss: 1.1905 - learning_rate: 5.0000e-04\n",
      "Epoch 67/100\n",
      "38/38 - 2s - 57ms/step - accuracy: 0.6732 - loss: 1.0428 - val_accuracy: 0.6901 - val_loss: 1.2086 - learning_rate: 5.0000e-04\n",
      "Epoch 68/100\n",
      "38/38 - 2s - 57ms/step - accuracy: 0.6779 - loss: 1.0519 - val_accuracy: 0.6064 - val_loss: 1.4376 - learning_rate: 5.0000e-04\n",
      "Epoch 69/100\n",
      "38/38 - 2s - 60ms/step - accuracy: 0.6833 - loss: 1.0135 - val_accuracy: 0.7002 - val_loss: 1.1744 - learning_rate: 5.0000e-04\n",
      "Epoch 70/100\n",
      "38/38 - 2s - 57ms/step - accuracy: 0.7005 - loss: 0.9834 - val_accuracy: 0.7253 - val_loss: 1.0910 - learning_rate: 5.0000e-04\n",
      "Epoch 71/100\n",
      "38/38 - 2s - 58ms/step - accuracy: 0.6921 - loss: 1.0145 - val_accuracy: 0.6951 - val_loss: 1.1095 - learning_rate: 5.0000e-04\n",
      "Epoch 72/100\n",
      "38/38 - 2s - 57ms/step - accuracy: 0.7047 - loss: 0.9739 - val_accuracy: 0.6985 - val_loss: 1.1644 - learning_rate: 5.0000e-04\n",
      "Epoch 73/100\n",
      "38/38 - 2s - 56ms/step - accuracy: 0.7034 - loss: 0.9717 - val_accuracy: 0.7186 - val_loss: 1.0956 - learning_rate: 5.0000e-04\n",
      "Epoch 74/100\n",
      "38/38 - 2s - 58ms/step - accuracy: 0.6992 - loss: 0.9987 - val_accuracy: 0.7203 - val_loss: 1.1097 - learning_rate: 5.0000e-04\n",
      "Epoch 75/100\n",
      "38/38 - 2s - 58ms/step - accuracy: 0.7055 - loss: 0.9449 - val_accuracy: 0.6901 - val_loss: 1.2898 - learning_rate: 5.0000e-04\n",
      "Epoch 76/100\n",
      "38/38 - 2s - 59ms/step - accuracy: 0.7202 - loss: 0.9310 - val_accuracy: 0.7387 - val_loss: 1.0775 - learning_rate: 2.5000e-04\n",
      "Epoch 77/100\n",
      "38/38 - 2s - 59ms/step - accuracy: 0.7185 - loss: 0.8820 - val_accuracy: 0.7186 - val_loss: 1.0906 - learning_rate: 2.5000e-04\n",
      "Epoch 78/100\n",
      "38/38 - 2s - 58ms/step - accuracy: 0.7299 - loss: 0.9099 - val_accuracy: 0.7035 - val_loss: 1.1214 - learning_rate: 2.5000e-04\n",
      "Epoch 79/100\n",
      "38/38 - 2s - 58ms/step - accuracy: 0.7341 - loss: 0.8909 - val_accuracy: 0.7303 - val_loss: 1.0429 - learning_rate: 2.5000e-04\n",
      "Epoch 80/100\n",
      "38/38 - 2s - 58ms/step - accuracy: 0.7450 - loss: 0.8570 - val_accuracy: 0.7337 - val_loss: 1.0348 - learning_rate: 2.5000e-04\n",
      "Epoch 81/100\n",
      "38/38 - 2s - 58ms/step - accuracy: 0.7383 - loss: 0.8816 - val_accuracy: 0.7303 - val_loss: 1.0465 - learning_rate: 2.5000e-04\n",
      "Epoch 82/100\n",
      "38/38 - 2s - 57ms/step - accuracy: 0.7336 - loss: 0.8899 - val_accuracy: 0.7286 - val_loss: 1.0467 - learning_rate: 2.5000e-04\n",
      "Epoch 83/100\n",
      "38/38 - 2s - 58ms/step - accuracy: 0.7404 - loss: 0.8680 - val_accuracy: 0.7538 - val_loss: 0.9997 - learning_rate: 2.5000e-04\n",
      "Epoch 84/100\n",
      "38/38 - 2s - 58ms/step - accuracy: 0.7475 - loss: 0.8204 - val_accuracy: 0.7672 - val_loss: 1.0130 - learning_rate: 2.5000e-04\n",
      "Epoch 85/100\n",
      "38/38 - 2s - 57ms/step - accuracy: 0.7408 - loss: 0.8430 - val_accuracy: 0.7655 - val_loss: 1.0069 - learning_rate: 2.5000e-04\n",
      "Epoch 86/100\n",
      "38/38 - 2s - 58ms/step - accuracy: 0.7542 - loss: 0.8430 - val_accuracy: 0.7370 - val_loss: 1.0154 - learning_rate: 2.5000e-04\n",
      "Epoch 87/100\n",
      "38/38 - 2s - 59ms/step - accuracy: 0.7404 - loss: 0.8353 - val_accuracy: 0.7337 - val_loss: 1.0466 - learning_rate: 2.5000e-04\n",
      "Epoch 88/100\n",
      "38/38 - 2s - 59ms/step - accuracy: 0.7605 - loss: 0.8152 - val_accuracy: 0.7588 - val_loss: 0.9876 - learning_rate: 2.5000e-04\n",
      "Epoch 89/100\n",
      "38/38 - 2s - 58ms/step - accuracy: 0.7445 - loss: 0.8112 - val_accuracy: 0.7722 - val_loss: 0.9547 - learning_rate: 2.5000e-04\n",
      "Epoch 90/100\n",
      "38/38 - 2s - 58ms/step - accuracy: 0.7576 - loss: 0.8084 - val_accuracy: 0.7688 - val_loss: 0.9624 - learning_rate: 2.5000e-04\n",
      "Epoch 91/100\n",
      "38/38 - 2s - 58ms/step - accuracy: 0.7672 - loss: 0.8003 - val_accuracy: 0.7688 - val_loss: 0.9722 - learning_rate: 2.5000e-04\n",
      "Epoch 92/100\n",
      "38/38 - 2s - 59ms/step - accuracy: 0.7739 - loss: 0.7647 - val_accuracy: 0.7772 - val_loss: 0.9426 - learning_rate: 2.5000e-04\n",
      "Epoch 93/100\n",
      "38/38 - 2s - 59ms/step - accuracy: 0.7693 - loss: 0.7802 - val_accuracy: 0.7789 - val_loss: 0.9298 - learning_rate: 2.5000e-04\n",
      "Epoch 94/100\n",
      "38/38 - 2s - 58ms/step - accuracy: 0.7731 - loss: 0.7660 - val_accuracy: 0.7789 - val_loss: 0.9124 - learning_rate: 2.5000e-04\n",
      "Epoch 95/100\n",
      "38/38 - 2s - 57ms/step - accuracy: 0.7706 - loss: 0.7769 - val_accuracy: 0.7688 - val_loss: 0.9356 - learning_rate: 2.5000e-04\n",
      "Epoch 96/100\n",
      "38/38 - 2s - 57ms/step - accuracy: 0.7706 - loss: 0.7557 - val_accuracy: 0.7688 - val_loss: 0.9367 - learning_rate: 2.5000e-04\n",
      "Epoch 97/100\n",
      "38/38 - 2s - 57ms/step - accuracy: 0.7760 - loss: 0.7471 - val_accuracy: 0.7755 - val_loss: 0.9377 - learning_rate: 2.5000e-04\n",
      "Epoch 98/100\n",
      "38/38 - 2s - 58ms/step - accuracy: 0.7810 - loss: 0.7557 - val_accuracy: 0.7755 - val_loss: 0.9210 - learning_rate: 2.5000e-04\n",
      "Epoch 99/100\n",
      "38/38 - 2s - 57ms/step - accuracy: 0.7836 - loss: 0.7504 - val_accuracy: 0.7822 - val_loss: 0.9344 - learning_rate: 2.5000e-04\n",
      "Epoch 100/100\n",
      "38/38 - 2s - 57ms/step - accuracy: 0.7785 - loss: 0.7539 - val_accuracy: 0.7889 - val_loss: 0.8955 - learning_rate: 1.2500e-04\n",
      "🔹 Val accuracy: 78.89%\n",
      "Saved Keras model → data/models\\asl_tcn_lstm.keras\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\lenovo\\AppData\\Local\\Temp\\tmpz_q137nu\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\lenovo\\AppData\\Local\\Temp\\tmpz_q137nu\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\lenovo\\AppData\\Local\\Temp\\tmpz_q137nu'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 16, 69), dtype=tf.float32, name='input_seq')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 29), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  1448130734736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1448130733856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1448131146848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1448131147200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1448131146320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1448131146496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1448131179792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1448131179616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1448131199392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1448131199568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1448131181552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1448131181728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1448131213440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1448131212560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1448131246384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1448131247440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1448131245680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1448131246208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1448131459904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1448131493200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1448131511392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1448131511040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1448131490736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1448131513680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1448131514208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1448131511568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1448131619120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1448131669680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1448131678624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1448131668624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1448131666336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1448131681088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1448131682144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1448131681440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1448131694256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1448131693904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1448153960112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1448153959760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1448154257008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1448154257184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1448154277488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1448154277312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "Saved TFLite model → data/models\\asl_tcn_lstm.tflite\n"
     ]
    }
   ],
   "source": [
    "# ─── Cell 5: TCN → Bi-LSTM → Attention Model Training ─────────────────\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv1D, BatchNormalization, Dropout, Masking, Add,\n",
    "    Bidirectional, LSTM, Dense, LayerNormalization, Layer\n",
    ")\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Paths\n",
    "MODEL_DIR        = \"data/models\"\n",
    "KERAS_MODEL_PATH = os.path.join(MODEL_DIR, \"asl_tcn_lstm.keras\")\n",
    "TFLITE_PATH      = os.path.join(MODEL_DIR, \"asl_tcn_lstm.tflite\")\n",
    "\n",
    "# ─── Split ─────────────────────────────────────────────────────────────\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# ─── Attention Layer ───────────────────────────────────────────────────\n",
    "class SimpleAttention(Layer):\n",
    "    def build(self, input_shape):\n",
    "        T, D = input_shape[1], input_shape[2]\n",
    "        self.W = self.add_weight((D,1), initializer=\"glorot_uniform\")\n",
    "        self.b = self.add_weight((T,1), initializer=\"zeros\")\n",
    "        super().build(input_shape)\n",
    "    def call(self, inputs):\n",
    "        e     = tf.matmul(inputs, self.W) + self.b\n",
    "        alpha = tf.nn.softmax(tf.nn.tanh(e), axis=1)\n",
    "        return tf.reduce_sum(inputs * alpha, axis=1)\n",
    "\n",
    "# ─── Model ─────────────────────────────────────────────────────────────\n",
    "NUM_FRAMES, FEATURE_DIM = X_train.shape[1], X_train.shape[2]\n",
    "NUM_CLASSES = len(np.unique(y))\n",
    "\n",
    "inp = Input(shape=(NUM_FRAMES, FEATURE_DIM), name=\"input_seq\")\n",
    "\n",
    "# TCN stem\n",
    "x = Masking(mask_value=0.0)(inp)\n",
    "x = Conv1D(64, 3, padding=\"causal\", activation=\"relu\",\n",
    "           kernel_regularizer=l2(1e-4))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "for dil in [2,4]:\n",
    "    res = x\n",
    "    x   = Conv1D(64, 3, padding=\"causal\", dilation_rate=dil,\n",
    "                 activation=\"relu\", kernel_regularizer=l2(1e-4))(x)\n",
    "    x   = BatchNormalization()(x)\n",
    "    x   = Dropout(0.3)(x)\n",
    "    x   = Add()([res, x])\n",
    "\n",
    "# Bi-LSTM stack\n",
    "x = Bidirectional(LSTM(128, return_sequences=True,\n",
    "                       kernel_regularizer=l2(1e-4),\n",
    "                       dropout=0.3, recurrent_dropout=0.3))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Bidirectional(LSTM(64, return_sequences=True,\n",
    "                       kernel_regularizer=l2(1e-4),\n",
    "                       dropout=0.3, recurrent_dropout=0.3))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "# Attention + head\n",
    "x = SimpleAttention()(x)\n",
    "x = Dense(64, activation=\"relu\", kernel_regularizer=l2(1e-4))(x)\n",
    "x = LayerNormalization()(x)\n",
    "x = Dropout(0.4)(x)\n",
    "out = Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
    "\n",
    "model = Model(inp, out, name=\"ASL_TCN_LSTM\")\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "# ─── Class Weights & Callbacks ─────────────────────────────────────────\n",
    "cw = compute_class_weight(\"balanced\", classes=np.unique(y_train), y=y_train)\n",
    "class_weights = dict(enumerate(cw))\n",
    "es = EarlyStopping(\"val_loss\", patience=15, restore_best_weights=True)\n",
    "rlr= ReduceLROnPlateau(\"val_loss\", factor=0.5, patience=5)\n",
    "\n",
    "# ─── Train ──────────────────────────────────────────────────────────────\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    callbacks=[es, rlr],\n",
    "    class_weight=class_weights,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# ─── Evaluate & Save ───────────────────────────────────────────────────\n",
    "loss, acc = model.evaluate(X_val, y_val, verbose=0)\n",
    "print(f\"🔹 Val accuracy: {acc*100:.2f}%\")\n",
    "\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "model.save(KERAS_MODEL_PATH)\n",
    "print(\"Saved Keras model →\", KERAS_MODEL_PATH)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS\n",
    "]\n",
    "tflite_model = converter.convert()\n",
    "open(TFLITE_PATH, \"wb\").write(tflite_model)\n",
    "print(\"Saved TFLite model →\", TFLITE_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd8445e-b3be-4c40-8a05-e38a158f874b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (signify-ml)",
   "language": "python",
   "name": "signify-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
